import numpy as np
import pandas as pd
import streamlit as st
from io import BytesIO


# å½’ä¸€åŒ–æ–¹æ³•å®šä¹‰ä¿æŒä¸å˜ï¼Œæ­¤å¤„çœç•¥ä»¥èŠ‚çœç¯‡å¹…
# [åŸæœ‰æ‰€æœ‰å½’ä¸€åŒ–å‡½æ•°å®šä¹‰...]
def min_max_normalize(data, feature_range=(0, 1)):
    """
    æœ€å°-æœ€å¤§å½’ä¸€åŒ–

    :param data: éœ€è¦å½’ä¸€åŒ–çš„è¾“å…¥æ•°æ®ï¼Œæ•°ç»„ç±»å‹
    :param feature_range: å½’ä¸€åŒ–åæ•°æ®çš„èŒƒå›´ï¼Œå…ƒç»„ (min, max)ï¼Œé»˜è®¤=(0, 1)
    :return: å½’ä¸€åŒ–åçš„æ•°æ®ï¼Œå½¢çŠ¶ä¸è¾“å…¥æ•°æ®ç›¸åŒ
    """
    data = np.asarray(data)
    min_val = np.min(data, axis=0)
    max_val = np.max(data, axis=0)

    std = (data - min_val) / (max_val - min_val)
    scaled = std * (feature_range[1] - feature_range[0]) + feature_range[0]

    return scaled

def z_score_normalize(data):
    """
    Z-scoreæ ‡å‡†åŒ–

    :param data: éœ€è¦å½’ä¸€åŒ–çš„è¾“å…¥æ•°æ®ï¼Œæ•°ç»„ç±»å‹
    :return: å½’ä¸€åŒ–åçš„æ•°æ®ï¼Œå½¢çŠ¶ä¸è¾“å…¥æ•°æ®ç›¸åŒ
    """
    data = np.asarray(data)
    mean = np.mean(data, axis=0)
    std = np.std(data, axis=0)

    return (data - mean) / std

def max_abs_normalize(data):
    """
    æœ€å¤§ç»å¯¹å€¼å½’ä¸€åŒ–

    :param data: éœ€è¦å½’ä¸€åŒ–çš„è¾“å…¥æ•°æ®ï¼Œæ•°ç»„ç±»å‹
    :return: å½’ä¸€åŒ–åçš„æ•°æ®ï¼Œå½¢çŠ¶ä¸è¾“å…¥æ•°æ®ç›¸åŒ
    """
    data = np.asarray(data)
    max_abs = np.max(np.abs(data), axis=0)

    return data / max_abs

def decimal_scaling_normalize(data):
    """
    å°æ•°å®šæ ‡å½’ä¸€åŒ–

    :param data: éœ€è¦å½’ä¸€åŒ–çš„è¾“å…¥æ•°æ®ï¼Œæ•°ç»„ç±»å‹
    :return: å½’ä¸€åŒ–åçš„æ•°æ®ï¼Œå½¢çŠ¶ä¸è¾“å…¥æ•°æ®ç›¸åŒ
    """
    data = np.asarray(data)
    max_val = np.max(np.abs(data), axis=0)
    j = np.ceil(np.log10(max_val)).astype(int)

    return data / (10 ** j)

def vector_normalize(data):
    """
    å‘é‡å½’ä¸€åŒ–(L2èŒƒæ•°å½’ä¸€åŒ–)

    :param data: éœ€è¦å½’ä¸€åŒ–çš„è¾“å…¥æ•°æ®ï¼Œæ•°ç»„ç±»å‹
    :return: å½’ä¸€åŒ–åçš„æ•°æ®ï¼Œå½¢çŠ¶ä¸è¾“å…¥æ•°æ®ç›¸åŒ
    """
    data = np.asarray(data)
    norm = np.linalg.norm(data, axis=1, keepdims=True)

    return data / norm

def log_normalize(data, base=np.e):
    """
    å¯¹æ•°å½’ä¸€åŒ–

    :param data: éœ€è¦å½’ä¸€åŒ–çš„è¾“å…¥æ•°æ®ï¼Œæ•°ç»„ç±»å‹
    :param base: å¯¹æ•°çš„åº•æ•°ï¼Œé»˜è®¤=e
    :return: å½’ä¸€åŒ–åçš„æ•°æ®ï¼Œå½¢çŠ¶ä¸è¾“å…¥æ•°æ®ç›¸åŒ
    """
    data = np.asarray(data)
    if np.any(data <= 0):
        st.text("å¯¹æ•°å½’ä¸€åŒ–è¦æ±‚æ‰€æœ‰å€¼å¿…é¡»ä¸ºæ­£")
        raise ValueError("å¯¹æ•°å½’ä¸€åŒ–è¦æ±‚æ‰€æœ‰å€¼å¿…é¡»ä¸ºæ­£")
    return np.log(data) / np.log(base)

def exp_normalize(data):
    """
    æŒ‡æ•°å½’ä¸€åŒ–

    :param data: éœ€è¦å½’ä¸€åŒ–çš„è¾“å…¥æ•°æ®ï¼Œæ•°ç»„ç±»å‹
    :return: å½’ä¸€åŒ–åçš„æ•°æ®ï¼Œå½¢çŠ¶ä¸è¾“å…¥æ•°æ®ç›¸åŒ
    """
    data = np.asarray(data)
    return np.exp(data - np.max(data, axis=0))

def softmax_normalize(data, axis=0):
    """
    Softmaxå½’ä¸€åŒ–

    :param data: éœ€è¦å½’ä¸€åŒ–çš„è¾“å…¥æ•°æ®ï¼Œæ•°ç»„ç±»å‹
    :param axis: è¿›è¡Œå½’ä¸€åŒ–çš„è½´ï¼Œé»˜è®¤=0
    :return: å½’ä¸€åŒ–åçš„æ•°æ®ï¼Œå½¢çŠ¶ä¸è¾“å…¥æ•°æ®ç›¸åŒ
    """
    data = np.asarray(data)
    exp_x = np.exp(data - np.max(data, axis=axis, keepdims=True))
    return exp_x / np.sum(exp_x, axis=axis, keepdims=True)


def generate_example_data(n_samples, n_features, add_noise=False, add_outliers=False):
    """ç”Ÿæˆç¤ºä¾‹æ•°æ®ï¼ŒåŒ…å«å¯é€‰å™ªå£°å’Œç¦»ç¾¤ç‚¹"""
    np.random.seed(42)
    base_data = np.random.rand(n_samples, n_features) * 100

    if add_noise:
        noise = np.random.normal(0, 10, (n_samples, n_features))
        base_data += noise

    if add_outliers:
        n_outliers = max(1, n_samples // 10)
        outlier_indices = np.random.choice(n_samples, n_outliers, replace=False)
        base_data[outlier_indices] += np.random.rand(n_outliers, n_features) * 500

    return base_data


# é¡µé¢å¸ƒå±€è®¾ç½®
st.set_page_config(layout="wide")
st.title("ğŸ§® æ•°æ®å½’ä¸€åŒ–/æ ‡å‡†åŒ–")

# ================= æ•°æ®è¾“å…¥éƒ¨åˆ† =================
with st.expander("ğŸ“Š æ•°æ®é…ç½®", expanded=True):
    data_source = st.radio(
        "è¯·é€‰æ‹©æ•°æ®æ¥æº",
        options=["ç”Ÿæˆç¤ºä¾‹æ•°æ®","è‡ªå®šä¹‰æ•°æ®"],
        horizontal=True
    )

    uploaded_file = None
    sheet_name = "Sheet1"
    example_data = None

    if data_source == "è‡ªå®šä¹‰æ•°æ®":
        st.subheader("ğŸ“¤ ä¸Šä¼ è‡ªå®šä¹‰æ•°æ®")
        with st.form("you_config"):
            uploaded_file = st.file_uploader("ä¸Šä¼ Excelæ–‡ä»¶", type=["xlsx", "xls"],
                                             help="æ¯è¡Œä¸€ä¸ªæ ·æœ¬ï¼Œæ¯åˆ—ä¸€ä¸ªç‰¹å¾")
            sheet_name = st.text_input("è¯·è¾“å…¥å·¥ä½œè¡¨åç§°æˆ–ç´¢å¼•ï¼Œé»˜è®¤å€¼ä¸ºâ€œSheet1â€", value="Sheet1")
            submit_upload = st.form_submit_button("ä¸Šä¼ æ•°æ®")
            if submit_upload:
                if uploaded_file is not None:
                    try:
                        df = pd.read_excel(uploaded_file, sheet_name=sheet_name)
                        st.session_state.normalize_current_data = df.values
                        st.session_state.normalize_data_source = "uploaded"
                        st.success("æ•°æ®ä¸Šä¼ æˆåŠŸï¼")
                    except Exception as e:
                        st.error(f"æ–‡ä»¶è¯»å–é”™è¯¯: {str(e)}")
                else:
                    st.warning("è¯·å…ˆä¸Šä¼ æ–‡ä»¶ã€‚")

    elif data_source == "ç”Ÿæˆç¤ºä¾‹æ•°æ®":
        st.subheader("âœ¨ ç”Ÿæˆç¤ºä¾‹æ•°æ®")
        with st.form("example_config"):
            a1, a2 = st.columns(2)
            n_samples = a1.number_input("æ ·æœ¬æ•°é‡", min_value=3, value=50)
            n_features = a2.number_input("ç‰¹å¾æ•°é‡", min_value=1, value=5)
            add_noise = a1.checkbox("æ·»åŠ å™ªå£°")
            add_outliers = a2.checkbox("æ·»åŠ ç¦»ç¾¤ç‚¹")
            submit_example = st.form_submit_button("ç”Ÿæˆæ•°æ®")
            if submit_example:
                example_data = generate_example_data(n_samples, n_features, add_noise, add_outliers)
                st.session_state.normalize_current_data = example_data
                st.session_state.normalize_data_source = "example"
                st.success("ç¤ºä¾‹æ•°æ®ç”ŸæˆæˆåŠŸï¼")

# æ•°æ®åˆå§‹åŒ–å’Œå›æ˜¾
if "normalize_current_data" not in st.session_state:
    # é»˜è®¤åˆå§‹åŒ–ä¸ºç¤ºä¾‹æ•°æ®
    st.session_state.normalize_current_data = generate_example_data(50, 5)
    st.session_state.normalize_data_source = "example"

# æ˜¾ç¤ºå½“å‰æ•°æ®
st.subheader("ğŸ‘€ å½“å‰æ•°æ®é¢„è§ˆ")
with st.expander("ğŸ“‹ å½“å‰æ•°æ®"):
    if st.session_state.normalize_data_source == "uploaded":
        preview_df = pd.DataFrame(
            st.session_state.normalize_current_data,
            columns=None
        )
        st.dataframe(preview_df)
    else:
        preview_df = pd.DataFrame(
            st.session_state.normalize_current_data,
            columns=[f"ç‰¹å¾{i + 1}" for i in range(st.session_state.normalize_current_data.shape[1])]
        )
        st.dataframe(preview_df)

# ================= å½’ä¸€åŒ–é…ç½®éƒ¨åˆ† =================
st.markdown("---")
st.subheader("âš™ï¸ å½’ä¸€åŒ–é…ç½®")
col1, col2 = st.columns([1,1])
with col1:
    methods = {
        "æœ€å°-æœ€å¤§å½’ä¸€åŒ–": {"func": min_max_normalize, "params": {"feature_range": (0, 1)}},
        "Z-Scoreæ ‡å‡†åŒ–": {"func": z_score_normalize},
        "æœ€å¤§ç»å¯¹å€¼å½’ä¸€åŒ–": {"func": max_abs_normalize},
        "å°æ•°å®šæ ‡å½’ä¸€åŒ–": {"func": decimal_scaling_normalize},
        "å‘é‡å½’ä¸€åŒ–(L2èŒƒæ•°)": {"func": vector_normalize},
        "å¯¹æ•°å½’ä¸€åŒ–": {"func": log_normalize, "params": {"base": np.e}},
        "Softmaxå½’ä¸€åŒ–": {"func": softmax_normalize}
    }

    selected_methods = st.multiselect(
        "ğŸ“ é€‰æ‹©å½’ä¸€åŒ–æ–¹æ³•",
        options=list(methods.keys()),
        default=["æœ€å°-æœ€å¤§å½’ä¸€åŒ–", "Z-Scoreæ ‡å‡†åŒ–"]
    )
with col2:
    # åŠ¨æ€å‚æ•°é…ç½®
    method_params = {}
    for method in selected_methods:
        if method == "æœ€å°-æœ€å¤§å½’ä¸€åŒ–":
            with st.expander(f"{method}å‚æ•°é…ç½®"):
                col_min, col_max = st.columns(2)
                min_val = col_min.number_input("æœ€å°å€¼", value=0.0, key=f"{method}_min")
                max_val = col_max.number_input("æœ€å¤§å€¼", value=1.0, key=f"{method}_max")
                method_params[method] = {"feature_range": (min_val, max_val)}

        if method == "å¯¹æ•°å½’ä¸€åŒ–":
            with st.expander(f"{method}å‚æ•°é…ç½®"):
                base = st.number_input("å¯¹æ•°åŸºæ•°", value=np.e, key=f"{method}_base")
                method_params[method] = {"base": base}

# ================= å¯è§†åŒ–éƒ¨åˆ† =================
st.markdown("---")
st.subheader("ğŸ“ˆ å¯è§†åŒ–ç»“æœ")

if st.button("ğŸš€ è¿è¡Œå½’ä¸€åŒ–"):
    data = st.session_state.normalize_current_data
    results = {"åŸå§‹æ•°æ®": data}

    for method in selected_methods:
        try:
            params = method_params.get(method, {})
            if method == "Softmaxå½’ä¸€åŒ–":
                normalized = methods[method]["func"](data, axis=0)
            else:
                normalized = methods[method]["func"](data, **params)
            results[method] = normalized
        except Exception as e:
            st.error(f"{method}æ‰§è¡Œå¤±è´¥: {str(e)}")

    st.session_state.normalize_results = results

if 'normalize_results' in st.session_state:
    feature_names = preview_df.columns.tolist()
    selected_feature = st.selectbox("ğŸ” é€‰æ‹©è¦å¯è§†åŒ–çš„ç‰¹å¾", feature_names)
    feature_idx = feature_names.index(selected_feature)

    # æ·»åŠ åŸå§‹æ•°æ®æ˜¾ç¤ºå¼€å…³
    show_raw = st.checkbox("æ˜¾ç¤ºåŸå§‹æ•°æ®", value=True, key='show_raw_data')

    # å‡†å¤‡æ•°æ®
    chart_data = {}
    for method, data in st.session_state.normalize_results.items():
        if method == "åŸå§‹æ•°æ®" and not show_raw:
            continue
        chart_data[method] = data[:, feature_idx]

    # è½¬æ¢ä¸ºDataFrame
    chart_df = pd.DataFrame(chart_data)
    chart_df.index.name = "æ ·æœ¬ç´¢å¼•"

    # ä½¿ç”¨Streamlitå†…ç½®æŠ˜çº¿å›¾
    st.line_chart(chart_df, use_container_width=True)

# ================= ç»“æœå¯¼å‡ºéƒ¨åˆ† =================
st.markdown("---")
if 'normalize_results' in st.session_state:
    st.subheader("ğŸ“¥ ç»“æœå¯¼å‡º")
    result_methods = [m for m in st.session_state.normalize_results if m != "åŸå§‹æ•°æ®"]
    cols = st.columns(len(result_methods))

    for idx, method in enumerate(result_methods):
        data = st.session_state.normalize_results[method]
        with cols[idx]:
            df_result = pd.DataFrame(data, columns=feature_names)
            # ç”ŸæˆExcelå­—èŠ‚æµ
            excel_buffer = BytesIO()
            with pd.ExcelWriter(excel_buffer, engine='openpyxl') as writer:
                df_result.to_excel(writer, index=False, sheet_name='Result')
            excel_bytes = excel_buffer.getvalue()
            st.download_button(
                label=f"â¬‡ï¸ ä¸‹è½½ {method} ç»“æœ",
                data=excel_bytes,
                file_name=f"{method}_result.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                key=f"btn_{method}"
            )

            if st.checkbox(f"ğŸ‘ï¸ æ˜¾ç¤º{method}ç»“æœ", key=f"cb_{method}"):
                st.dataframe(df_result)