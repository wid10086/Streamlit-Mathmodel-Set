import streamlit as st
import numpy as np
import pandas as pd

# ================= å·¥å…·æ–¹æ³•å®šä¹‰ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ä¸å˜ï¼‰ =================
# [åŸæœ‰ahp(), topsis(), fuzzy_evaluation(), entropy_weight_method()å®šä¹‰...]

def ahp(criteria_matrix, alternative_matrices=None):
    """
    å±‚æ¬¡åˆ†ææ³• (Analytic Hierarchy Process, AHP)

    :param criteria_matrix: å‡†åˆ™å±‚åˆ¤æ–­çŸ©é˜µï¼ŒäºŒç»´æ•°ç»„
    :param alternative_matrices: æ–¹æ¡ˆå±‚åˆ¤æ–­çŸ©é˜µåˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ªäºŒç»´æ•°ç»„ï¼Œå¯¹åº”ä¸€ä¸ªå‡†åˆ™
    :return: å¦‚æœæä¾›äº†æ–¹æ¡ˆå±‚åˆ¤æ–­çŸ©é˜µï¼Œåˆ™è¿”å›æ¯ä¸ªæ–¹æ¡ˆçš„æœ€ç»ˆå¾—åˆ†ï¼›å¦åˆ™è¿”å›å‡†åˆ™å±‚æƒé‡
    """

    # æ£€æŸ¥åˆ¤æ–­çŸ©é˜µæ˜¯å¦ä¸ºæ–¹é˜µä¸”å¯¹è§’çº¿å…ƒç´ ä¸º1
    def check_matrix(matrix):
        if matrix.shape[0] != matrix.shape[1]:
            st.warning("åˆ¤æ–­çŸ©é˜µå¿…é¡»æ˜¯æ–¹é˜µ")
            st.stop()
        if not np.allclose(np.diag(matrix), 1):
            st.warning("åˆ¤æ–­çŸ©é˜µå¯¹è§’çº¿å…ƒç´ å¿…é¡»ä¸º1")
            st.stop()

    check_matrix(criteria_matrix)

    # è®¡ç®—å‡†åˆ™å±‚æƒé‡
    eigenvalues, eigenvectors = np.linalg.eig(criteria_matrix)
    max_eigenvalue_index = np.argmax(eigenvalues)
    criteria_weights = np.real(eigenvectors[:, max_eigenvalue_index] / np.sum(eigenvectors[:, max_eigenvalue_index]))

    # ä¸€è‡´æ€§æ£€éªŒ
    n = criteria_matrix.shape[0]
    RI = [0, 0, 0.58, 0.9, 1.12, 1.24, 1.32, 1.41, 1.45, 1.49]  # éšæœºä¸€è‡´æ€§æŒ‡æ ‡
    CI = (eigenvalues[max_eigenvalue_index] - n) / (n - 1)
    CR = CI / RI[n - 1] if n > 2 else 0 # å½“n=1,2æ—¶ï¼Œæ€»æ˜¯å®Œå…¨ä¸€è‡´çš„

    if CR >= 0.1:
        st.text("è­¦å‘Šï¼šå‡†åˆ™å±‚ä¸€è‡´æ€§æ£€éªŒæœªé€šè¿‡ (CR >= 0.1)")

    if alternative_matrices is None:
        st.text(f"å‡†åˆ™å±‚ä¸€è‡´æ€§æ¯”ç‡ CR: {CR:.4f}")
        return criteria_weights

    # è®¡ç®—æ–¹æ¡ˆå±‚æƒé‡
    alternative_weights = []
    for i, alternative_matrix in enumerate(alternative_matrices):
        check_matrix(alternative_matrix)

        eigenvalues, eigenvectors = np.linalg.eig(alternative_matrix)
        max_eigenvalue_index = np.argmax(eigenvalues)
        weights = np.real(eigenvectors[:, max_eigenvalue_index] / np.sum(eigenvectors[:, max_eigenvalue_index]))

        # ä¸€è‡´æ€§æ£€éªŒ
        n_alt = alternative_matrix.shape[0]
        CI_alt = (eigenvalues[max_eigenvalue_index] - n_alt) / (n_alt - 1)
        CR_alt = CI_alt / RI[n_alt - 1] if n_alt > 2 else 0

        st.text(f"æ–¹æ¡ˆå±‚ï¼ˆå‡†åˆ™ {i+1}ï¼‰ä¸€è‡´æ€§æ¯”ç‡ CR: {CR_alt:.4f}")
        if CR_alt >= 0.1:
          st.text(f"è­¦å‘Šï¼šæ–¹æ¡ˆå±‚ï¼ˆå‡†åˆ™ {i+1}ï¼‰ä¸€è‡´æ€§æ£€éªŒæœªé€šè¿‡ (CR >= 0.1)")

        alternative_weights.append(weights)

    alternative_weights = np.array(alternative_weights)

    # è®¡ç®—æœ€ç»ˆå¾—åˆ†
    final_scores = np.dot(criteria_weights, alternative_weights)

    return final_scores

def topsis(data_matrix, weights, benefit_attributes):
    """
    TOPSIS æ³• (Technique for Order Preference by Similarity to an Ideal Solution)

    :param data_matrix: å†³ç­–çŸ©é˜µï¼ŒäºŒç»´æ•°ç»„ï¼Œæ¯ä¸€è¡Œæ˜¯ä¸€ä¸ªæ–¹æ¡ˆï¼Œæ¯ä¸€åˆ—æ˜¯ä¸€ä¸ªå±æ€§
    :param weights: å±æ€§æƒé‡ï¼Œä¸€ç»´æ•°ç»„
    :param benefit_attributes: æ•ˆç›Šå±æ€§ï¼ˆè¶Šå¤§è¶Šå¥½ï¼‰çš„ç´¢å¼•åˆ—è¡¨ï¼Œä¾‹å¦‚ [0, 2] è¡¨ç¤ºç¬¬1ä¸ªå’Œç¬¬3ä¸ªå±æ€§æ˜¯æ•ˆç›Šå±æ€§
    :return: æ¯ä¸ªæ–¹æ¡ˆçš„ç›¸å¯¹æ¥è¿‘åº¦
    """
    data_matrix = np.asarray(data_matrix)
    weights = np.asarray(weights)
    # æ–°å¢æƒé‡å½’ä¸€åŒ–
    weights = weights / np.sum(weights)
    # 1. è§„èŒƒåŒ–å†³ç­–çŸ©é˜µ
    normalized_matrix = data_matrix / np.linalg.norm(data_matrix, axis=0)

    # 2. åŠ æƒè§„èŒƒåŒ–å†³ç­–çŸ©é˜µ
    weighted_matrix = normalized_matrix * weights

    # 3. ç¡®å®šæ­£ç†æƒ³è§£å’Œè´Ÿç†æƒ³è§£
    positive_ideal_solution = np.zeros(data_matrix.shape[1])
    negative_ideal_solution = np.zeros(data_matrix.shape[1])
    for i in range(data_matrix.shape[1]):
        if i in benefit_attributes:
            positive_ideal_solution[i] = np.max(weighted_matrix[:, i])
            negative_ideal_solution[i] = np.min(weighted_matrix[:, i])
        else:
            positive_ideal_solution[i] = np.min(weighted_matrix[:, i])
            negative_ideal_solution[i] = np.max(weighted_matrix[:, i])

    # 4. è®¡ç®—æ¯ä¸ªæ–¹æ¡ˆåˆ°æ­£ç†æƒ³è§£å’Œè´Ÿç†æƒ³è§£çš„è·ç¦»
    distance_to_positive = np.linalg.norm(weighted_matrix - positive_ideal_solution, axis=1)
    distance_to_negative = np.linalg.norm(weighted_matrix - negative_ideal_solution, axis=1)

    # 5. è®¡ç®—æ¯ä¸ªæ–¹æ¡ˆçš„ç›¸å¯¹æ¥è¿‘åº¦
    closeness = distance_to_negative / (distance_to_positive + distance_to_negative + 1e-8)

    return closeness

def fuzzy_evaluation(criteria_weights, membership_degrees, evaluation_levels):
    """
    æ¨¡ç³Šç»¼åˆè¯„ä»·æ³• (Fuzzy Comprehensive Evaluation)

    :param criteria_weights: å‡†åˆ™æƒé‡, ä¸€ç»´æ•°ç»„
    :param membership_degrees: å„æ–¹æ¡ˆåœ¨å„å‡†åˆ™ä¸‹çš„éš¶å±åº¦çŸ©é˜µ, ä¸‰ç»´æ•°ç»„,
                               ç¬¬ä¸€ç»´ä¸ºæ–¹æ¡ˆ, ç¬¬äºŒç»´ä¸ºå‡†åˆ™, ç¬¬ä¸‰ç»´ä¸ºè¯„è¯­ç­‰çº§
    :param evaluation_levels: è¯„è¯­ç­‰çº§æƒé‡, ä¸€ç»´æ•°ç»„
    :return: å„æ–¹æ¡ˆçš„æ¨¡ç³Šç»¼åˆè¯„ä»·å¾—åˆ†
    """
    criteria_weights = np.asarray(criteria_weights)
    membership_degrees = np.asarray(membership_degrees)
    evaluation_levels = np.asarray(evaluation_levels)

    # å¤„ç†äºŒç»´è¾“å…¥ï¼ˆå•æ–¹æ¡ˆæƒ…å†µï¼‰
    if membership_degrees.ndim == 2:
        membership_degrees = membership_degrees[np.newaxis, :, :]

    # æ£€æŸ¥ç»´åº¦æ˜¯å¦åŒ¹é…
    if membership_degrees.shape[1] != criteria_weights.shape[0]:
        st.warning("éš¶å±åº¦çŸ©é˜µçš„å‡†åˆ™ç»´åº¦ä¸å‡†åˆ™æƒé‡ç»´åº¦ä¸åŒ¹é…")
        st.stop()
    if membership_degrees.shape[2] != evaluation_levels.shape[0]:
        st.warning("éš¶å±åº¦çŸ©é˜µçš„è¯„è¯­ç­‰çº§ç»´åº¦ä¸è¯„è¯­ç­‰çº§æƒé‡ç»´åº¦ä¸åŒ¹é…")
        st.stop()

    # å½’ä¸€åŒ–å‡†åˆ™æƒé‡
    criteria_weights = criteria_weights / criteria_weights.sum()

    # è®¡ç®—æ¨¡ç³Šç»¼åˆè¯„ä»·çŸ©é˜µ
    evaluation_matrix = np.dot(criteria_weights, membership_degrees)

    # å¤„ç†å¯èƒ½çš„é™¤é›¶é”™è¯¯
    sum_eval = np.sum(evaluation_matrix, axis=1, keepdims=True)
    if np.any(sum_eval == 0):
        st.warning("å­˜åœ¨æ–¹æ¡ˆçš„åˆæˆéš¶å±åº¦æ€»å’Œä¸ºé›¶ï¼Œå¯èƒ½å¯¼è‡´ç»“æœå¼‚å¸¸")
        sum_eval[sum_eval == 0] = 1  # é¿å…é™¤é›¶

    evaluation_matrix = evaluation_matrix / sum_eval

    # è®¡ç®—æœ€ç»ˆå¾—åˆ†
    final_scores = np.dot(evaluation_matrix, evaluation_levels)

    return final_scores

def entropy_weight_method(data_matrix):
    """
    ç†µæƒæ³• (Entropy Weight Method) ä»…é€‚ç”¨äºé‚£äº›å˜å¼‚ç¨‹åº¦èƒ½å¤Ÿåæ˜ æŒ‡æ ‡é‡è¦ç¨‹åº¦çš„æƒ…å†µ

    :param data_matrix: å†³ç­–çŸ©é˜µï¼ŒäºŒç»´æ•°ç»„ï¼Œæ¯ä¸€è¡Œæ˜¯ä¸€ä¸ªæ–¹æ¡ˆï¼Œæ¯ä¸€åˆ—æ˜¯ä¸€ä¸ªå±æ€§
    :return: å„ä¸ªå±æ€§çš„æƒé‡
    """
    data_matrix = np.asarray(data_matrix)

    # 1. è§„èŒƒåŒ–å†³ç­–çŸ©é˜µ
    normalized_matrix = data_matrix / np.sum(data_matrix, axis=0)

    # 2. è®¡ç®—æ¯ä¸ªå±æ€§çš„ä¿¡æ¯ç†µ
    k = -1 / np.log(data_matrix.shape[0])
    entropy = np.zeros(data_matrix.shape[1])
    for j in range(data_matrix.shape[1]):
      entropy[j] = k * np.sum(normalized_matrix[:, j] * np.log(normalized_matrix[:, j] + 1e-10)) # é¿å… log(0) é”™è¯¯

    # 3. è®¡ç®—æ¯ä¸ªå±æ€§çš„ç†µæƒ
    weights = (1 - entropy) / np.sum(1 - entropy)

    return weights

# ================= é¡µé¢é…ç½® =================
st.set_page_config(layout="wide")
st.title("ğŸ“Š å¤šå‡†åˆ™å†³ç­–åˆ†æ/è¯„ä¼°")
criteria_names = []
ways_name = []
st.session_state.eval_data = None

# ================= ä¾§è¾¹æ  - æ–¹æ³•é€‰æ‹© =================
with st.container(border= True):
    st.markdown("### âš™ï¸ é…ç½®")
    col1, col2 = st.columns(2)
    with col1:
        n_features = st.number_input("ğŸ”¢ ç‰¹å¾/å‡†åˆ™æ•°é‡", min_value=2, max_value=10, value=3, key="evaluate_n_features")
        way_num = st.number_input("ğŸ§‘â€ğŸ¤â€ğŸ§‘ æ–¹æ¡ˆæ•°", min_value=1, max_value=10, value=1, key="way_num")
        method = st.selectbox(
            "ğŸ§® é€‰æ‹©åˆ†ææ–¹æ³•",
            ["AHP", "TOPSIS", "æ¨¡ç³Šç»¼åˆè¯„ä»·", "ç†µæƒæ³•"],
            key="evaluate_method"
        )

    with col2:
        with st.expander("ğŸ“ è‡ªå®šä¹‰å‡†åˆ™åç§°(ä¸å¯é‡å)"):
            for i in range(n_features):
                criteria_names.append(st.text_input(f"å‡†åˆ™{i + 1}", value=f"C{i + 1}"))
        with st.expander("ğŸ“ è‡ªå®šä¹‰æ–¹æ¡ˆåç§°(ä¸å¯é‡å)"):
            for i in range(way_num):
                ways_name.append(st.text_input(f"æ–¹æ¡ˆ{i + 1}", value=f"P{i + 1}"))
        if method =="TOPSIS" or method == "ç†µæƒæ³•":
            with st.expander("ğŸ“¤ è‡ªå®šä¹‰æ–‡ä»¶ä¸Šä¼ "):
                with st.form("æ–‡ä»¶ä¸Šä¼ "):
                    file = st.file_uploader(f"ä¾ç…§ç¤ºä¾‹æ ¼å¼ä¸Šä¼ æ•°æ®æ–‡ä»¶ï¼ˆç¬¬ä¸€åˆ—ä¸ºæ•°æ®ï¼Œä¸æ˜¯åˆ—åï¼‰,", type=["xlsx", "xls"])
                    sheet = st.text_input(f"æ•°æ®å·¥ä½œè¡¨åï¼ˆExcelï¼‰", value="Sheet1")
                    if st.form_submit_button("æ•°æ®ä¸Šä¼ "):
                        if file:
                            data = pd.read_excel(file,sheet_name=sheet)
                            criteria_names = data.columns.tolist()
                            st.session_state.eval_data = data
                            ways_name = data.index.tolist()
                            n_features = len(criteria_names)
                            way_num = len(ways_name)
                        else:
                            st.text("æ— ä¸Šä¼ æ–‡ä»¶")
                            st.session_state.eval_data = None


# ================= æ–¹æ³•å‚æ•°é…ç½® =================
params = {}

@st.fragment()
def fun(method,n_features,way_num):
    with st.container(border=True):
        row = st.columns(3)
        row[0].markdown("#### âš™ï¸ å‚æ•°é…ç½®")
        character = criteria_names
        show = row[1].checkbox("ğŸ‘ï¸ æŸ¥çœ‹çŸ©é˜µ")
        if method == "AHP":
            row = st.columns(2)
            with row[0]:
                with st.expander("ğŸŸ¦ å‡†åˆ™ç›¸å¯¹é‡è¦ç¨‹åº¦ï¼ˆ1/9~9,åªéœ€å¡«å†™å³ä¸Šæ–¹è¡¨æ ¼ï¼‰", expanded=True):
                    st.markdown("å¡«å†™åˆ¤æ–­çŸ©é˜µï¼Œa(i,j)>1è¡¨ç¤ºiæ¯”jæ›´é‡è¦ï¼Œa(i,j)<1è¡¨ç¤ºiæ¯”jæ›´ä¸é‡è¦ã€‚ä¸»å¯¹è§’çº¿å¿…é¡»ä¸º1ã€‚")
                    # é»˜è®¤ç”Ÿæˆ1çš„çŸ©é˜µ
                    matrix_df = pd.DataFrame(np.ones((n_features, n_features)), index=criteria_names, columns=criteria_names)
                    for i in range(n_features):
                        for j in range(i):
                            matrix_df.iloc[i, j] = None
                    # å…è®¸ç”¨æˆ·ç¼–è¾‘ä¸Šä¸‰è§’ï¼ˆä¸å«å¯¹è§’çº¿ï¼‰ï¼Œä¸‹ä¸‰è§’è‡ªåŠ¨å¡«1/å€¼
                    edited_df = st.data_editor(
                        matrix_df,
                        key="ahp_matrix_editor",
                        num_rows="fixed",
                        use_container_width=True
                    )
                    # ä¿è¯ä¸»å¯¹è§’çº¿ä¸º1ï¼Œä¸‹ä¸‰è§’ä¸ºä¸Šä¸‰è§’çš„å€’æ•°
                    for i in range(n_features):
                        edited_df.iloc[i, i] = 1.0
                        for j in range(i+1, n_features):
                            edited_df.iloc[j, i] = 1.0 / edited_df.iloc[i, j]
                    matrix = edited_df.values

                criteria_matrix = pd.DataFrame(matrix, index=criteria_names, columns=criteria_names)
                if show:
                    st.markdown("å‡†åˆ™å±‚åˆ¤æ–­çŸ©é˜µ")
                    st.dataframe(criteria_matrix, key="criteria")
            with row[1]:
                alternative_matrices = []
                with st.container( border=True):
                    st.markdown("#### ğŸŸ© AHPæ–¹æ¡ˆå±‚(å¾—åˆ†è§„åˆ™åŒå‡†åˆ™ç›¸å¯¹é‡è¦ç¨‹åº¦) ")
                    for i in range(n_features):
                        # é»˜è®¤ç”Ÿæˆ1çš„çŸ©é˜µ
                        alt_matrix_df = pd.DataFrame(np.ones((way_num, way_num)), index=ways_name, columns=ways_name)
                        for j in range(way_num):
                            for k in range(j):
                                alt_matrix_df.iloc[j, k] = None
                        with st.expander(f"{criteria_names[i]}ä¸­å„æ–¹æ¡ˆç›¸å¯¹å¾—åˆ†ï¼ˆå¡«å†™ä¸Šä¸‰è§’ï¼Œä¸»å¯¹è§’çº¿ä¸º1ï¼‰"):
                            edited_alt_df = st.data_editor(
                                alt_matrix_df,
                                key=f"ahp_alt_matrix_editor_{i}",
                                num_rows="fixed",
                                use_container_width=True
                            )
                            # ä¿è¯ä¸»å¯¹è§’çº¿ä¸º1ï¼Œä¸‹ä¸‰è§’ä¸ºä¸Šä¸‰è§’çš„å€’æ•°
                            for j in range(way_num):
                                edited_alt_df.iloc[j, j] = 1.0
                                for k in range(j+1, way_num):
                                    edited_alt_df.iloc[k, j] = 1.0 / edited_alt_df.iloc[j, k]
                            x = edited_alt_df.values
                            if show:
                                st.dataframe(pd.DataFrame(x,index=ways_name,columns=ways_name),key=f"æ–¹æ¡ˆ{i}")
                        alternative_matrices.append(x)
            params['criteria_matrix'] = criteria_matrix.values
            params['alternative_matrices'] = alternative_matrices

        elif method == "TOPSIS":
            data_matrix_topsis = np.ones((way_num, n_features))
            if st.session_state.eval_data is None:
                    # æ„å»ºé»˜è®¤æ•°æ®è¡¨
                data_matrix_df = pd.DataFrame(
                    np.ones((way_num, n_features)),
                    index=ways_name,
                    columns=criteria_names
                )
                # å…è®¸ç”¨æˆ·ç›´æ¥ç¼–è¾‘æ•´ä¸ªè¡¨æ ¼
                edited_df = st.data_editor(
                    data_matrix_df,
                    key="topsis_data_matrix_editor" ,
                    num_rows="fixed",
                    use_container_width=True
                )
                data_matrix_topsis = edited_df.values 
            else:
                st.text("å·²å­˜åœ¨æ–‡ä»¶")
                data_matrix_topsis = st.session_state.eval_data.values
            with st.expander("ğŸŸ¨ å‡†åˆ™æƒé‡(ä¼šè‡ªåŠ¨å½’ä¸€åŒ–)"):
                # æ„å»ºæƒé‡è¡¨æ ¼
                weights_df = pd.DataFrame(
                    np.ones((1, n_features)) / n_features,
                    columns=criteria_names,
                    index=["æƒé‡"]
                )
                edited_weights_df = st.data_editor(
                    weights_df,
                    key="topsis_weights_editor",
                    num_rows="fixed",
                    use_container_width=True
                )
                topsis_weights = edited_weights_df.values

                params["weights_topsis"] = topsis_weights
            params["benefit_attributes_topsis"] = st.multiselect(
                "âœ¨ é€‰æ‹©æ•ˆç›Šå±æ€§ï¼ˆè¶Šå¤§è¶Šå¥½çš„ç‰¹å¾,æœªé€‰ç‰¹å¾å³ä¸ºè¶Šå¤§è¶Šåçš„ç‰¹å¾ï¼‰",
                options=list(range(n_features)),
                format_func=lambda x: f"{criteria_names[x]}"
            )
            if show:
                st.text("å†³ç­–çŸ©é˜µ")
                st.dataframe(pd.DataFrame(data_matrix_topsis,index=ways_name,columns=character),key="å†³ç­–çŸ©é˜µ")
            params["data_matrix_topsis"] = data_matrix_topsis

        elif method == "æ¨¡ç³Šç»¼åˆè¯„ä»·":
            cols=st.columns(2)
            with cols[0]:
                eval_num = st.number_input("ğŸ”¢ è¯„è¯­ç­‰çº§æ•°é‡",min_value=2,max_value=5,value=3)
                evaluation_levels_fuzzy = np.zeros(eval_num)
                str_k = ['ä¼˜','è¾ƒä¼˜','ä¸­','è¾ƒå·®','å·®']
                if eval_num ==2:
                    str_eval = [str_k[0],str_k[4]]
                elif eval_num==3:
                    str_eval = [str_k[0],str_k[2],str_k[4]]
                elif eval_num==4:
                    str_eval = [str_k[0],str_k[2],str_k[3],str_k[4]]
                elif eval_num==5:
                    str_eval = str_k
                with st.expander("ğŸŸª è¯„è¯­ç­‰çº§è®¾ç½®"):
                    col = st.columns(eval_num)
                    for i in range(eval_num):
                        level_value = col[i].number_input(
                            f"è¯„è¯­ç­‰çº§ {str_eval[i]} çš„å€¼",
                            min_value=0.0,
                            max_value=1.0,
                            value=1.0 - i *1.0/eval_num,  # é»˜è®¤å€¼é€’å‡
                            step=0.1,
                            key=f"level_{i}"
                        )
                        evaluation_levels_fuzzy[i] = level_value
                    # éªŒè¯è¯„è¯­ç­‰çº§å€¼æ˜¯å¦é€’å‡
                    is_valid = True
                    for i in range(1, eval_num):
                        if evaluation_levels_fuzzy[i] >= evaluation_levels_fuzzy[i - 1]:
                            is_valid = False
                            break
                    # æ˜¾ç¤ºéªŒè¯ç»“æœ
                    if is_valid:
                        st.success("è¯„è¯­ç­‰çº§å€¼è®¾ç½®æ­£ç¡®ï¼ˆé€’å‡ï¼‰")
                    else:
                        st.error("è¯„è¯­ç­‰çº§å€¼è®¾ç½®é”™è¯¯ï¼šå€¼å¿…é¡»æ˜¯é€’å‡çš„ï¼")
                criteria_weights_fuzzy = np.ones(n_features)
                with st.expander("ğŸŸ¨ å‡†åˆ™æƒé‡(ä¼šè‡ªåŠ¨å½’ä¸€åŒ–)"):
                    col = st.columns((n_features))
                    for i in range(n_features):
                        criteria_weights_fuzzy[i] = col[i].number_input(f"{criteria_names[i]}", key=f"å‡†åˆ™æƒé‡{criteria_names[i]}",
                                                                    min_value=0.0, value=1.0 / n_features)

                params["criteria_weights_fuzzy"] = criteria_weights_fuzzy

                params["evaluation_levels_fuzzy"] = evaluation_levels_fuzzy
            with cols[1]:
                with st.container(border=True):
                    st.markdown("#### ğŸŸ§ æ¨¡ç³Šç»¼åˆè¯„ä»·æ–¹æ¡ˆï¼ˆç›´æ¥åœ¨è¡¨æ ¼ä¸­å¡«å†™å„æ–¹æ¡ˆçš„éš¶å±åº¦ï¼‰")
                    membership_degrees_fuzzy = []
                    for i in range(way_num):
                        # æ„å»ºä¸åŸæ¥ä¸€è‡´çš„é»˜è®¤éš¶å±åº¦çŸ©é˜µ
                        default_values = np.zeros((n_features, eval_num))
                        for j in range(n_features):
                            for k in range(eval_num):
                                default_values[j, k] = 1.0 - 1 * k / eval_num
                        fuzzy_df = pd.DataFrame(
                            default_values,
                            index=criteria_names,
                            columns=str_eval
                        )
                        # å…è®¸ç”¨æˆ·ç›´æ¥ç¼–è¾‘æ•´ä¸ªè¡¨æ ¼
                        edited_fuzzy_df = st.data_editor(
                            fuzzy_df,
                            key=f"fuzzy_membership_{i}",
                            num_rows="fixed",
                            use_container_width=True
                        )
                        a = edited_fuzzy_df.values
                        if show:
                            st.dataframe(pd.DataFrame(a, index=criteria_names, columns=str_eval), key=f"{ways_name[i]}éš¶å±åº¦")
                        membership_degrees_fuzzy.append(a)
                    params['membership_degrees_fuzzy'] = np.array(membership_degrees_fuzzy)
        elif method == "ç†µæƒæ³•":
            if st.session_state.eval_data is None:
                with st.expander("ğŸŸ¦ ä¸åŒæ–¹æ¡ˆåœ¨ä¸åŒå‡†åˆ™çš„å±æ€§"):
                    # æ„å»ºé»˜è®¤æ•°æ®è¡¨
                    data_matrix_df = pd.DataFrame(
                        np.ones((way_num, n_features)),
                        index=ways_name,
                        columns=criteria_names
                    )
                    # å…è®¸ç”¨æˆ·ç›´æ¥ç¼–è¾‘æ•´ä¸ªè¡¨æ ¼
                    edited_df = st.data_editor(
                        data_matrix_df,
                        key="entropy_data_matrix_editor",
                        num_rows="fixed",
                        use_container_width=True
                    )
                    data_matrix_entropy = edited_df.values
            else:
                st.text("å·²å­˜åœ¨æ–‡ä»¶")
                data_matrix_entropy = st.session_state.eval_data.values
            if show:
                st.text("å†³ç­–çŸ©é˜µ")
                st.dataframe(pd.DataFrame(data_matrix_entropy, index=ways_name, columns=character), key="å†³ç­–çŸ©é˜µ")
            params['data_matrix_entropy'] = data_matrix_entropy
        if st.button("ğŸš€ å¼€å§‹è®¡ç®—"):
            #params
            st.markdown("---")
            if method == "AHP":
                criteria_weights = ahp(params['criteria_matrix'])
                st.write(f"å±‚æ¬¡åˆ†ææ³• - å‡†åˆ™å±‚æƒé‡: {criteria_weights}")
                st.markdown("---")
                final_scores_ahp = ahp(params['criteria_matrix'], params['alternative_matrices'])
                st.markdown("---")
                row = st.columns(2)
                row[0].write(f"å±‚æ¬¡åˆ†ææ³• - æ–¹æ¡ˆæœ€ç»ˆå¾—åˆ†:")
                f = {}
                for i in range(way_num):
                    f[ways_name[i]]=final_scores_ahp[i]
                    row[0].write(f"{ways_name[i]}: {final_scores_ahp[i]}")
                row[1].bar_chart(f)
            elif method == "TOPSIS":
                closeness = topsis(params['data_matrix_topsis'], params['weights_topsis'], params['benefit_attributes_topsis'])
                row = st.columns(2)
                row[0].write(f"TOPSISæ³• - æ–¹æ¡ˆç›¸å¯¹æ¥è¿‘åº¦:")
                f = {}
                for i in range(way_num):
                    f[ways_name[i]] = closeness[i]
                    row[0].write(f"{ways_name[i]}: {closeness[i]}")
                row[1].bar_chart(f)

            elif method == "æ¨¡ç³Šç»¼åˆè¯„ä»·":
                final_scores_fuzzy = fuzzy_evaluation(params['criteria_weights_fuzzy'], params['membership_degrees_fuzzy'],
                                                      params['evaluation_levels_fuzzy'])
                row = st.columns(2)
                row[0].write(f"æ¨¡ç³Šç»¼åˆè¯„ä»·æ³• - æ–¹æ¡ˆæœ€ç»ˆå¾—åˆ†:")
                f = {}
                for i in range(way_num):
                    f[ways_name[i]] = final_scores_fuzzy[i]
                    row[0].write(f"{ways_name[i]}: {final_scores_fuzzy[i]}")
                row[1].bar_chart(f)

            elif method == "ç†µæƒæ³•":
                weights_entropy = entropy_weight_method(params['data_matrix_entropy'])
                st.write(f"ç†µæƒæ³• - å±æ€§æƒé‡: {weights_entropy}")
                row = st.columns(2)
                row[0].write(f"ç†µæƒæ³• - å±æ€§æƒé‡:")
                f = {}
                for i in range(n_features):
                    f[criteria_names[i]] = weights_entropy[i]
                    row[0].write(f"{criteria_names[i]}: {weights_entropy[i]}")
                row[1].bar_chart(f)
fun(method,n_features,way_num)
