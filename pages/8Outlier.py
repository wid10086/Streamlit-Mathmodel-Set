import numpy as np
import pandas as pd
import streamlit as st
from io import BytesIO
from scipy import interpolate, signal
from sklearn.cluster import DBSCAN
from sklearn.ensemble import IsolationForest
from sklearn.svm import OneClassSVM
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans


# --- å¼‚å¸¸å€¼æ£€æµ‹å’Œå‰”é™¤ ---

def std_dev_outlier(data, threshold=3):
    """
    æ ‡å‡†å·®æ–¹æ³•æ£€æµ‹å¼‚å¸¸å€¼
    :param data: è¾“å…¥æ•°æ®ï¼Œä¸€ç»´æ•°ç»„æˆ–Series
    :param threshold: å¼‚å¸¸å€¼é˜ˆå€¼ï¼Œé»˜è®¤3ä¸ªæ ‡å‡†å·®
    :return: å‰”é™¤å¼‚å¸¸å€¼åçš„æ•°æ®
    """
    data = np.asarray(data)
    mean = np.mean(data)
    std = np.std(data)
    lower_bound = mean - threshold * std
    upper_bound = mean + threshold * std
    filtered_data = data[(data >= lower_bound) & (data <= upper_bound)]
    return filtered_data


def iqr_outlier(data, k=1.5):
    """
    ç®±çº¿å›¾ (IQR) æ–¹æ³•æ£€æµ‹å¼‚å¸¸å€¼
    :param data: è¾“å…¥æ•°æ®ï¼Œä¸€ç»´æ•°ç»„æˆ–Series
    :param k: IQRå€æ•°ï¼Œç”¨äºè®¡ç®—ä¸Šä¸‹é™ï¼Œé»˜è®¤1.5
    :return: å‰”é™¤å¼‚å¸¸å€¼åçš„æ•°æ®
    """
    data = np.asarray(data)
    q1 = np.percentile(data, 25)
    q3 = np.percentile(data, 75)
    iqr = q3 - q1
    lower_bound = q1 - k * iqr
    upper_bound = q3 + k * iqr
    filtered_data = data[(data >= lower_bound) & (data <= upper_bound)]
    return filtered_data


def z_score_outlier(data, threshold=3):
    """
    Zåˆ†æ•°æ–¹æ³•æ£€æµ‹å¼‚å¸¸å€¼
    :param data: è¾“å…¥æ•°æ®ï¼Œä¸€ç»´æ•°ç»„æˆ–Series
    :param threshold: Zåˆ†æ•°é˜ˆå€¼ï¼Œé»˜è®¤3
    :return: å‰”é™¤å¼‚å¸¸å€¼åçš„æ•°æ®
    """
    data = np.asarray(data)
    mean = np.mean(data)
    std = np.std(data)
    z_scores = (data - mean) / std
    filtered_data = data[np.abs(z_scores) <= threshold]
    return filtered_data


def dbscan_outlier(data, eps=0.5, min_samples=5):
    """
    DBSCAN ç®—æ³•æ£€æµ‹å¼‚å¸¸å€¼ï¼ŒDBSCAN å°†æ•°æ®ç‚¹åˆ†ä¸ºæ ¸å¿ƒç‚¹ã€è¾¹ç•Œç‚¹å’Œå™ªå£°ç‚¹ï¼Œå™ªå£°ç‚¹å³ä¸ºå¼‚å¸¸å€¼ã€‚
    :param data: è¾“å…¥æ•°æ®ï¼ŒäºŒç»´æ•°ç»„æˆ–DataFrame
    :param eps: DBSCAN åŠå¾„å‚æ•°ï¼Œç”¨äºå®šä¹‰é‚»åŸŸå¤§å°
    :param min_samples: é‚»åŸŸå†…çš„æœ€å°æ ·æœ¬æ•°ï¼Œç”¨äºå®šä¹‰æ ¸å¿ƒç‚¹
    :return: å‰”é™¤å¼‚å¸¸å€¼åçš„æ•°æ®
    """
    data = np.asarray(data)
    dbscan = DBSCAN(eps=eps, min_samples=min_samples)
    labels = dbscan.fit_predict(data)
    filtered_data = data[labels != -1]
    return filtered_data


def kmeans_outlier(data, n_clusters=3, threshold=2):
    """
        K-means ç®—æ³•æ£€æµ‹å¼‚å¸¸å€¼ï¼Œåˆ©ç”¨èšç±»ä¸­å¿ƒä¸æ•°æ®ç‚¹çš„è·ç¦»åˆ¤æ–­å¼‚å¸¸å€¼
        :param data: è¾“å…¥æ•°æ®ï¼ŒäºŒç»´æ•°ç»„æˆ–DataFrame
        :param n_clusters: èšç±»ä¸­å¿ƒæ•°é‡
        :param threshold: å¼‚å¸¸å€¼è·ç¦»ä¸­å¿ƒç‚¹çš„é˜ˆå€¼
        :return: å‰”é™¤å¼‚å¸¸å€¼åçš„æ•°æ®
    """
    data = np.asarray(data)
    kmeans = KMeans(n_clusters=n_clusters, random_state=0, n_init=10)
    kmeans.fit(data)
    distances = kmeans.transform(data)
    labels = np.argmin(distances, axis=1)

    # è®¡ç®—æ¯ä¸ªç‚¹åˆ°å¯¹åº”èšç±»ä¸­å¿ƒçš„è·ç¦»
    distances_to_center = distances[np.arange(len(data)), labels]

    # é€‰å–è·ç¦»ä¸­å¿ƒç‚¹è¶…è¿‡é˜ˆå€¼çš„ç‚¹ä½œä¸ºå¼‚å¸¸å€¼
    filtered_data = data[distances_to_center <= threshold]
    return filtered_data


def isolation_forest_outlier(data, contamination='auto'):
    """
       Isolation Forest ç®—æ³•æ£€æµ‹å¼‚å¸¸å€¼
        :param data: è¾“å…¥æ•°æ®ï¼ŒäºŒç»´æ•°ç»„æˆ–DataFrame
        :param contamination: å¼‚å¸¸å€¼æ¯”ä¾‹ï¼Œé»˜è®¤ 'auto'
        :return: å‰”é™¤å¼‚å¸¸å€¼åçš„æ•°æ®
    """
    data = np.asarray(data)
    isolation_forest = IsolationForest(contamination=contamination, random_state=0)
    labels = isolation_forest.fit_predict(data)
    filtered_data = data[labels == 1]
    return filtered_data


def one_class_svm_outlier(data, nu=0.1, kernel="rbf", gamma="scale"):
    """
       One-Class SVM ç®—æ³•æ£€æµ‹å¼‚å¸¸å€¼
        :param data: è¾“å…¥æ•°æ®ï¼ŒäºŒç»´æ•°ç»„æˆ–DataFrame
        :param nu: å¼‚å¸¸å€¼æ¯”ä¾‹ï¼Œé»˜è®¤0.1
        :param kernel: æ ¸å‡½æ•°ç±»å‹
        :param gamma: æ ¸å‡½æ•°å‚æ•°
        :return: å‰”é™¤å¼‚å¸¸å€¼åçš„æ•°æ®
    """
    data = np.asarray(data)
    oneclass_svm = OneClassSVM(nu=nu, kernel=kernel, gamma=gamma)
    labels = oneclass_svm.fit_predict(data)
    filtered_data = data[labels == 1]
    return filtered_data


# --- æ’å€¼æ–¹æ³• ---
def linear_interpolation(x, y, x_new):
    """
        çº¿æ€§æ’å€¼ï¼Œä½¿ç”¨ç›´çº¿è¿æ¥æ•°æ®ç‚¹ã€‚
        :param x: åŸå§‹æ•°æ®ç‚¹çš„ x åæ ‡
        :param y: åŸå§‹æ•°æ®ç‚¹çš„ y åæ ‡
        :param x_new: éœ€è¦æ’å€¼çš„æ–°çš„ x åæ ‡
        :return: æ’å€¼åçš„ y å€¼
    """
    f = interpolate.interp1d(x, y, kind='linear', fill_value="extrapolate")
    return f(x_new)


def polynomial_interpolation(x, y, x_new, degree=3):
    """
        å¤šé¡¹å¼æ’å€¼ï¼Œç”¨ä¸€ä¸ªå¤šé¡¹å¼å‡½æ•°æ¥æ‹Ÿåˆæ•°æ®ç‚¹ã€‚
        :param x: åŸå§‹æ•°æ®ç‚¹çš„ x åæ ‡
        :param y: åŸå§‹æ•°æ®ç‚¹çš„ y åæ ‡
        :param x_new: éœ€è¦æ’å€¼çš„æ–°çš„ x åæ ‡
        :param degree: å¤šé¡¹å¼æ¬¡æ•°ï¼Œé»˜è®¤ä¸º3
        :return: æ’å€¼åçš„ y å€¼
    """
    f = interpolate.interp1d(x, y, kind=degree, fill_value="extrapolate")
    return f(x_new)


def spline_interpolation(x, y, x_new, k=3):
    """
       æ ·æ¡æ’å€¼ï¼Œä½¿ç”¨åˆ†æ®µå¤šé¡¹å¼å‡½æ•°æ¥æ‹Ÿåˆæ•°æ®ç‚¹ã€‚
       :param x: åŸå§‹æ•°æ®ç‚¹çš„ x åæ ‡
       :param y: åŸå§‹æ•°æ®ç‚¹çš„ y åæ ‡
       :param x_new: éœ€è¦æ’å€¼çš„æ–°çš„ x åæ ‡
       :param k: æ ·æ¡æ’å€¼çš„é˜¶æ•°ï¼Œé»˜è®¤ä¸º3
       :return: æ’å€¼åçš„ y å€¼
   """


    f = interpolate.splrep(x, y, s=0, k=k)
    return interpolate.splev(x_new, f)


def nearest_neighbor_interpolation(x, y, x_new):
    """
       æœ€è¿‘é‚»æ’å€¼ï¼Œä½¿ç”¨ç¦»æ’å€¼ç‚¹æœ€è¿‘çš„æ•°æ®ç‚¹çš„å€¼ä½œä¸ºæ’å€¼ç»“æœã€‚
       :param x: åŸå§‹æ•°æ®ç‚¹çš„ x åæ ‡
       :param y: åŸå§‹æ•°æ®ç‚¹çš„ y åæ ‡
       :param x_new: éœ€è¦æ’å€¼çš„æ–°çš„ x åæ ‡
       :return: æ’å€¼åçš„ y å€¼
   """


    f = interpolate.interp1d(x, y, kind='nearest', fill_value="extrapolate")
    return f(x_new)


def rbf_interpolation(x, y, x_new, function='multiquadric', epsilon=2):
    """
      å¾„å‘åŸºå‡½æ•°ï¼ˆRBFï¼‰æ’å€¼ï¼Œä½¿ç”¨å¾„å‘åŸºå‡½æ•°æ‹Ÿåˆæ•°æ®ç‚¹ã€‚
      :param x: åŸå§‹æ•°æ®ç‚¹çš„ x åæ ‡
      :param y: åŸå§‹æ•°æ®ç‚¹çš„ y åæ ‡
      :param x_new: éœ€è¦æ’å€¼çš„æ–°çš„ x åæ ‡
      :param function: RBF å‡½æ•°ç±»å‹ï¼Œé»˜è®¤ä¸º 'multiquadric'
      :param epsilon: RBF å‡½æ•°çš„å½¢çŠ¶å‚æ•°
      :return: æ’å€¼åçš„ y å€¼
  """


    f = interpolate.Rbf(x, y, function=function, epsilon=epsilon)
    return f(x_new)


def fourier_interpolation(x, y, x_new):
    """
      å‚…é‡Œå¶æ’å€¼ï¼Œé€šè¿‡å‚…é‡Œå¶å˜æ¢åœ¨é¢‘åŸŸä¸­å¯¹æ•°æ®è¿›è¡Œæ’å€¼ã€‚
      :param x: åŸå§‹æ•°æ®ç‚¹çš„ x åæ ‡
      :param y: åŸå§‹æ•°æ®ç‚¹çš„ y åæ ‡
      :param x_new: éœ€è¦æ’å€¼çš„æ–°çš„ x åæ ‡
      :return: æ’å€¼åçš„ y å€¼
  """


    n = len(x)
    y_fft = np.fft.fft(y)
    x_new_n = len(x_new)
    y_new_fft = np.zeros(x_new_n, dtype=complex)
    y_new_fft[:n // 2] = y_fft[:n // 2]
    y_new_fft[-n // 2:] = y_fft[-n // 2:]
    y_new = np.fft.ifft(y_new_fft).real

    # æ’å€¼åé•¿åº¦å¯èƒ½ä¸x_newä¸åŒï¼Œéœ€è¦æˆªå–
    if len(y_new) > len(x_new):
        y_new = y_new[:len(x_new)]

    return y_new


# --- æ•°æ®å¹³æ»‘æ–¹æ³• ---
def median_filter(data, window_size=3):
    """
       ä¸­å€¼æ»¤æ³¢ï¼Œä½¿ç”¨çª—å£ä¸­å€¼æ›¿æ¢ä¸­å¿ƒå€¼ï¼Œå¯ä»¥æœ‰æ•ˆå»é™¤è„‰å†²å™ªå£°ã€‚
       :param data: è¾“å…¥æ•°æ®ï¼Œä¸€ç»´æ•°ç»„æˆ–Series
       :param window_size: çª—å£å¤§å°ï¼Œå¿…é¡»ä¸ºå¥‡æ•°ï¼Œé»˜è®¤ä¸º3
       :return: å¹³æ»‘åçš„æ•°æ®
    """
    return signal.medfilt(data, kernel_size=window_size)


def mean_filter(data, window_size=3):
    """
        å‡å€¼æ»¤æ³¢ï¼Œä½¿ç”¨çª—å£å‡å€¼æ›¿æ¢ä¸­å¿ƒå€¼ï¼Œå¯ä»¥æœ‰æ•ˆå‡å°‘éšæœºå™ªå£°ã€‚
        :param data: è¾“å…¥æ•°æ®ï¼Œä¸€ç»´æ•°ç»„æˆ–Series
        :param window_size: çª—å£å¤§å°ï¼Œé»˜è®¤ä¸º3
        :return: å¹³æ»‘åçš„æ•°æ®
    """
    window = np.ones(window_size) / window_size
    return np.convolve(data, window, mode='same')


def low_pass_filter(data, cutoff_freq=0.1, order=5):
    """
         ä½é€šæ»¤æ³¢ï¼Œæ»¤é™¤é«˜é¢‘ä¿¡å·ï¼Œä¿ç•™ä½é¢‘ä¿¡å·ã€‚
        :param data: è¾“å…¥æ•°æ®ï¼Œä¸€ç»´æ•°ç»„æˆ–Series
        :param cutoff_freq: æˆªæ­¢é¢‘ç‡ï¼Œå½’ä¸€åŒ–é¢‘ç‡
        :param order: æ»¤æ³¢å™¨é˜¶æ•°ï¼Œé»˜è®¤ä¸º5
        :return: å¹³æ»‘åçš„æ•°æ®
    """
    b, a = signal.butter(order, cutoff_freq, btype='low', analog=False)
    return signal.filtfilt(b, a, data)


def kalman_filter(data, initial_state=0, initial_covariance=1, process_noise=0.1, measurement_noise=1):
    """
        å¡å°”æ›¼æ»¤æ³¢ï¼Œé€šè¿‡é¢„æµ‹å’Œæ›´æ–°æ­¥éª¤é€’å½’ä¼°è®¡ä¿¡å·çŠ¶æ€ã€‚
        :param data: è¾“å…¥æ•°æ®ï¼Œä¸€ç»´æ•°ç»„æˆ–Series
        :param initial_state: åˆå§‹çŠ¶æ€ä¼°è®¡å€¼
        :param initial_covariance: åˆå§‹çŠ¶æ€ä¼°è®¡åæ–¹å·®
        :param process_noise: è¿‡ç¨‹å™ªå£°åæ–¹å·®
        :param measurement_noise: æµ‹é‡å™ªå£°åæ–¹å·®
        :return: å¹³æ»‘åçš„æ•°æ®
    """
    n = len(data)
    filtered_state_estimates = np.zeros(n)

    state = initial_state  # åˆå§‹çŠ¶æ€
    covariance = initial_covariance  # åˆå§‹åæ–¹å·®

    for i, measurement in enumerate(data):
        # é¢„æµ‹æ­¥éª¤
        predicted_state = state
        predicted_covariance = covariance + process_noise

        # æ›´æ–°æ­¥éª¤
        kalman_gain = predicted_covariance / (predicted_covariance + measurement_noise)
        state = predicted_state + kalman_gain * (measurement - predicted_state)
        covariance = (1 - kalman_gain) * predicted_covariance

        filtered_state_estimates[i] = state

    return filtered_state_estimates


def autoregressive_smoothing(data, p=3, alpha=0.9):
    """
      è‡ªå›å½’å¹³æ»‘ï¼Œé€šè¿‡å‰å‡ ä¸ªæ•°æ®ç‚¹çš„å€¼é¢„æµ‹å½“å‰å€¼ã€‚
      :param data: è¾“å…¥æ•°æ®ï¼Œä¸€ç»´æ•°ç»„æˆ–Series
      :param p: è‡ªå›å½’æ¨¡å‹çš„é˜¶æ•°ï¼Œé»˜è®¤ä¸º3
      :param alpha: å¹³æ»‘ç³»æ•°ï¼Œé»˜è®¤ä¸º0.9
      :return: å¹³æ»‘åçš„æ•°æ®
    """
    n = len(data)
    smoothed_data = np.copy(data)
    for t in range(p, n):
        ar_part = np.sum(smoothed_data[t - p:t] * alpha)
        smoothed_data[t] = (1 - alpha) * data[t] + ar_part
    return smoothed_data

# é…ç½®é¡µé¢
st.set_page_config(layout="wide", page_title="æ•°æ®é¢„å¤„ç†åˆ†æå¹³å°")
st.title("æ•°æ®é¢„å¤„ç†/å¼‚å¸¸å€¼å¤„ç†")

# ================= ä¼šè¯çŠ¶æ€åˆå§‹åŒ– =================
if 'outlier_data' not in st.session_state:
    st.session_state.outlier_data = None
if 'outlier_processed' not in st.session_state:
    st.session_state.outlier_processed = None

# ================= æ•°æ®é…ç½®æ¨¡å— =================
with st.expander("ğŸ“Š æ•°æ®é…ç½®", expanded=True):
    data_col1, data_col2 = st.columns([1, 2])

    with data_col1:
        st.subheader("ç¤ºä¾‹æ•°æ®ç”Ÿæˆ")
        method_type = st.selectbox("é€‰æ‹©å¤„ç†æ–¹æ³•ç±»å‹", ["å¼‚å¸¸å€¼æ£€æµ‹", "æ’å€¼å¤„ç†", "æ•°æ®å¹³æ»‘"])

        # é€šç”¨å‚æ•°é…ç½®
        n_samples = st.number_input("æ ·æœ¬æ•°é‡", 50, 1000, 200)
        n_features = st.number_input("ç‰¹å¾æ•°é‡", 1, 10, 3)
        add_noise = st.checkbox("æ·»åŠ å™ªå£°")

        # æ ¹æ®æ–¹æ³•ç±»å‹ç”Ÿæˆä¸åŒç¤ºä¾‹æ•°æ®
        np.random.seed(42)
        X = np.random.randn(n_samples, n_features)
        time_axis = np.linspace(0, 10, n_samples)  # æ—¶é—´è½´ç”¨äºæ’å€¼å’Œå¹³æ»‘

        if method_type == "å¼‚å¸¸å€¼æ£€æµ‹":
            outlier_idx = np.random.choice(n_samples, size=5, replace=False)
            X[outlier_idx] += 10  # æ·»åŠ å¼‚å¸¸å€¼

        elif method_type == "æ’å€¼å¤„ç†":
            # ç”Ÿæˆå¸¦æ—¶é—´ç»´åº¦çš„æ•°æ®
            X = np.column_stack([time_axis] + [np.sin(time_axis + i) for i in range(n_features - 1)])

        else:  # æ•°æ®å¹³æ»‘
            # ç”Ÿæˆå¸¦å™ªå£°çš„ä¿¡å·æ•°æ®
            X = np.column_stack([time_axis] + [
                np.sin(time_axis * (i + 1)) + np.random.normal(0, 0.5, n_samples)
                for i in range(n_features - 1)
            ])

        if add_noise:
            X += np.random.normal(0, 0.3, X.shape)

        if st.button("ç”Ÿæˆç¤ºä¾‹æ•°æ®ï¼ˆä¸åŒæ–¹æ³•çš„ç¤ºä¾‹æ•°æ®å¯èƒ½ä¸åŒï¼‰"):
            columns = ["æ—¶é—´"] + [f"ä¿¡å·_{i}" for i in range(n_features - 1)] if method_type != "å¼‚å¸¸å€¼æ£€æµ‹" \
                else [f"ç‰¹å¾_{i}" for i in range(n_features)]
            df = pd.DataFrame(X, columns=columns)
            st.session_state.outlier_data = df
            st.success("ç¤ºä¾‹æ•°æ®ç”ŸæˆæˆåŠŸï¼")

    with data_col2:
        st.subheader("ä¸Šä¼ è‡ªå®šä¹‰æ•°æ®")
        uploaded_file = st.file_uploader("é€‰æ‹©CSV/Excelæ–‡ä»¶", type=["csv", "xlsx"])
        if uploaded_file:
            try:
                if uploaded_file.name.endswith('.csv'):
                    df = pd.read_csv(uploaded_file)
                else:
                    df = pd.read_excel(uploaded_file)
                st.session_state.outlier_data = df
                st.success("æ•°æ®åŠ è½½æˆåŠŸï¼")
            except Exception as e:
                st.error(f"æ•°æ®åŠ è½½é”™è¯¯: {str(e)}")

# ================= æ•°æ®é¢„è§ˆ =================
if st.session_state.outlier_data is not None:
    with st.expander("ğŸ” æ•°æ®é¢„è§ˆ", expanded=True):
        df = st.session_state.outlier_data
        cols = st.columns([3, 1])
        cols[0].dataframe(df.style.highlight_null(color='yellow'), height=300)
        cols[1].markdown(f"**æ•°æ®ç»´åº¦**: {df.shape}")

# ================= æ–¹æ³•é€‰æ‹©ä¸å‚æ•°é…ç½® =================
method_params = {}
selected_features = []
if st.session_state.outlier_data is not None:
    with st.expander("âš™ï¸ å¤„ç†é…ç½®", expanded=True):
        df = st.session_state.outlier_data

        # ç‰¹å¾é€‰æ‹©
        available_features = df.columns.tolist()
        base_feature = "æ—¶é—´" if method_type != "å¼‚å¸¸å€¼æ£€æµ‹" else None

        selected_features = st.multiselect(
            "é€‰æ‹©å¤„ç†ç‰¹å¾ï¼ˆå¤šé€‰ï¼‰",
            available_features,
            default=[f for f in available_features if f != "æ—¶é—´"]
        )

        # æ–¹æ³•é€‰æ‹©
        if method_type == "å¼‚å¸¸å€¼æ£€æµ‹":
            method = st.selectbox("é€‰æ‹©æ£€æµ‹æ–¹æ³•", [
                "æ ‡å‡†å·®æ³•", "IQRæ³•", "Zåˆ†æ•°æ³•",
                "DBSCAN", "K-means", "å­¤ç«‹æ£®æ—", "One-Class SVM"
            ])
            st.text("åå››ç§æ–¹æ³•å»ºè®®å¤šç‰¹å¾åŒæ—¶å¤„ç†")

            if method in ["æ ‡å‡†å·®æ³•", "IQRæ³•", "Zåˆ†æ•°æ³•"]:
                method_params["threshold"] = st.slider("å¼‚å¸¸é˜ˆå€¼", 1.0, 5.0, 3.0)
            elif method == "DBSCAN":
                method_params["eps"] = st.slider("é‚»åŸŸåŠå¾„", 0.1, 2.0, 0.5)
                method_params["min_samples"] = st.number_input("æœ€å°æ ·æœ¬æ•°", 2, 20, 5)
            elif method == "K-means":
                method_params["n_clusters"] = st.number_input("èšç±»æ•°é‡", 2, 10, 3)
                method_params["threshold"] = st.slider("è·ç¦»é˜ˆå€¼", 1.0, 5.0, 2.0)

        elif method_type == "æ’å€¼å¤„ç†":
            method = st.selectbox("é€‰æ‹©æ’å€¼æ–¹æ³•", [
                "çº¿æ€§æ’å€¼", "å¤šé¡¹å¼æ’å€¼", "æ ·æ¡æ’å€¼",
                "æœ€è¿‘é‚»æ’å€¼", "RBFæ’å€¼", "å‚…é‡Œå¶æ’å€¼"
            ])
            if method == "å¤šé¡¹å¼æ’å€¼":
                method_params["degree"] = st.number_input("å¤šé¡¹å¼æ¬¡æ•°", 1, 5, 3)
            elif method == "æ ·æ¡æ’å€¼":
                method_params["k"] = st.number_input("æ ·æ¡é˜¶æ•°", 1, 5, 3)
            elif method == "RBFæ’å€¼":
                method_params["function"] = st.selectbox("æ ¸å‡½æ•°", [
                    "multiquadric", "gaussian", "inverse", "linear"
                ])

        else:  # æ•°æ®å¹³æ»‘
            method = st.selectbox("é€‰æ‹©å¹³æ»‘æ–¹æ³•", [
                "ä¸­å€¼æ»¤æ³¢", "å‡å€¼æ»¤æ³¢", "ä½é€šæ»¤æ³¢",
                "å¡å°”æ›¼æ»¤æ³¢", "è‡ªå›å½’å¹³æ»‘"
            ])
            if method == "ä¸­å€¼æ»¤æ³¢":
                method_params["window_size"] = st.slider("çª—å£å¤§å°", 3, 15, 5, step=2)
            elif method == "ä½é€šæ»¤æ³¢":
                method_params["cutoff_freq"] = st.slider("æˆªæ­¢é¢‘ç‡", 0.01, 0.5, 0.1)
            elif method == "è‡ªå›å½’å¹³æ»‘":
                method_params["p"] = st.number_input("å›å½’é˜¶æ•°", 1, 10, 3)

# ================= æ‰§è¡Œå¤„ç† =================
if st.button("å¼€å§‹å¤„ç†") and st.session_state.outlier_data is not None:
    df = st.session_state.outlier_data
    processed_data = df.copy()

    try:
        for feature in selected_features:
            data = df[feature].values

            if method_type == "å¼‚å¸¸å€¼æ£€æµ‹":
                # å¤šå˜é‡æ–¹æ³•å•ç‹¬å¤„ç†
                if method in ["DBSCAN", "K-means", "å­¤ç«‹æ£®æ—", "One-Class SVM"]:
                    data_2d = df[selected_features].values

                    if method == "DBSCAN":
                        filtered_idx = dbscan_outlier(data_2d, **method_params)
                    elif method == "K-means":
                        filtered_idx = kmeans_outlier(data_2d, **method_params)
                    elif method == "å­¤ç«‹æ£®æ—":
                        filtered_idx = isolation_forest_outlier(data_2d)
                    elif method == "One-Class SVM":
                        filtered_idx = one_class_svm_outlier(data_2d)

                     # ç”Ÿæˆå¸ƒå°”æ©ç ï¼ˆæ”¹è¿›æ–¹æ¡ˆï¼‰
                    mask = np.array([np.any(np.all(np.isclose(row, filtered_idx), axis=1))
                               for row in data_2d])
                    processed_data = df[mask]

                else:  # å•å˜é‡æ–¹æ³•é€ä¸ªå¤„ç†
                    valid_indices = set(range(len(df)))  # åˆå§‹åŒ–æœ‰æ•ˆç´¢å¼•é›†åˆ

                    for feature in selected_features:
                        data = df[feature].values

                        if method == "æ ‡å‡†å·®æ³•":
                            filtered = std_dev_outlier(data, method_params.get("threshold", 3))
                        elif method == "IQRæ³•":
                            filtered = iqr_outlier(data, method_params.get("k", 1.5))
                        elif method == "Zåˆ†æ•°æ³•":
                            filtered = z_score_outlier(data, method_params.get("threshold", 3))

                        # è·å–å½“å‰ç‰¹å¾çš„åˆæ³•ç´¢å¼•
                        feature_valid = np.isin(df[feature].values, filtered)
                        valid_indices.intersection_update(np.where(feature_valid)[0])

                    # åº”ç”¨æ‰€æœ‰ç‰¹å¾çš„å…±åŒæœ‰æ•ˆç´¢å¼•
                    processed_data = df.iloc[list(valid_indices)]

            elif method_type == "æ’å€¼å¤„ç†":
                # è·å–æ—¶é—´è½´æ•°æ®
                time_old = df["æ—¶é—´"].values
                time_new = np.linspace(time_old.min(), time_old.max(), n_samples * 2)

                # æ›´æ–°å¤„ç†åçš„æ—¶é—´è½´
                processed_data = pd.DataFrame({"æ—¶é—´": time_new})

                for feature in selected_features:
                    y_old = df[feature].values

                    if method == "çº¿æ€§æ’å€¼":
                        y_new = linear_interpolation(time_old, y_old, time_new)
                    elif method == "å¤šé¡¹å¼æ’å€¼":
                        y_new = polynomial_interpolation(time_old, y_old, time_new, method_params.get("degree", 3))
                    elif method == "æ ·æ¡æ’å€¼":
                        y_new = spline_interpolation(time_old, y_old, time_new, method_params.get("k", 3))
                    elif method == "æœ€è¿‘é‚»æ’å€¼":
                        y_new = nearest_neighbor_interpolation(time_old, y_old, time_new)
                    elif method == "RBFæ’å€¼":
                        y_new = rbf_interpolation(time_old, y_old, time_new,
                                                  method_params.get("function", "multiquadric"))
                    else:  # å‚…é‡Œå¶æ’å€¼
                        y_new = fourier_interpolation(time_old, y_old, time_new)

                    processed_data[feature] = y_new[:len(time_new)]

            else:  # æ•°æ®å¹³æ»‘
                for feature in selected_features:
                    data = df[feature].values

                    if method == "ä¸­å€¼æ»¤æ³¢":
                        smoothed = median_filter(data, method_params.get("window_size", 3))
                    elif method == "å‡å€¼æ»¤æ³¢":
                        smoothed = mean_filter(data, method_params.get("window_size", 3))
                    elif method == "ä½é€šæ»¤æ³¢":
                        smoothed = low_pass_filter(data, method_params.get("cutoff_freq", 0.1))
                    elif method == "å¡å°”æ›¼æ»¤æ³¢":
                        smoothed = kalman_filter(data)
                    else:  # è‡ªå›å½’å¹³æ»‘
                        smoothed = autoregressive_smoothing(data, method_params.get("p", 3))
                    processed_data[feature] = smoothed

        st.session_state.outlier_processed = processed_data
        st.success("å¤„ç†å®Œæˆï¼")

    except Exception as e:
        st.error(f"å¤„ç†å¤±è´¥: {str(e)}")

# ================= ç»“æœå±•ç¤º =================
if st.session_state.outlier_processed is not None:
    with st.expander("ğŸ“ˆ å¤„ç†ç»“æœ", expanded=True):
        col1, col2 = st.columns([3, 1])

        with col1:
            st.subheader("æ•°æ®å¯¹æ¯”")
            show_original = st.checkbox("æ˜¾ç¤ºåŸå§‹æ•°æ®")

            for feature in selected_features:
                df_plot = pd.DataFrame({
                    "åŸå§‹æ•°æ®": st.session_state.outlier_data[feature],
                    "å¤„ç†ç»“æœ": st.session_state.outlier_processed[feature]
                })
                if not show_original:
                    df_plot = df_plot.drop(columns=["åŸå§‹æ•°æ®"])
                st.text(feature)
                st.line_chart(df_plot, height=200)

        with col2:
            st.subheader("æ•°æ®ä¸‹è½½")
            st.session_state.outlier_processed
            excel_buffer = BytesIO()
            with pd.ExcelWriter(excel_buffer, engine='openpyxl') as writer:
                st.session_state.outlier_processed.to_excel(writer, index=False)

            st.download_button(
                label="ä¸‹è½½å¤„ç†ç»“æœ",
                data=excel_buffer.getvalue(),
                file_name="processed_data.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )